{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working demonstration of KINS injector using the Census Income dataset\n",
    "\n",
    "Notebook organisation:\n",
    "1. [**imports and utility functions**](#imports)\n",
    "2. [**dataset description, analysis and preprocessing**](#dataset-description,-analysis-and-preprocessing)\n",
    "3. [**injection**](#injection) (if you are interested only in the injection mechanism skip the other parts)\n",
    "4. [**training and evaluation**](#training-and-evaluation)\n",
    "\n",
    "Note: Internet connection is required to download the dataset.\n",
    "If the files of the Census Income dataset are in folder `data` Internet connection is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports and utility functions\n",
    "\n",
    "Some necessary imports:\n",
    "- __os__ to use other resources in this repository\n",
    "- __pandas__ for data retrieval and statistics\n",
    "- __tensorflow__ for reproducibility of neural networks training\n",
    "- __psyki__ for symbolic knowledge injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.python.framework.random_seed import set_seed\n",
    "from psyki.logic import Theory\n",
    "from psyki.logic.prolog import TuProlog\n",
    "from psyki.ski import Injector\n",
    "\n",
    "os.getcwd()\n",
    "from knowledge import PATH as KNOWLEDGE_PATH\n",
    "from data import CensusIncome\n",
    "from utils import create_uneducated_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macro definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENSUS_KNOWLEDGE_FILE = str(KNOWLEDGE_PATH / CensusIncome.knowledge_file_name)\n",
    "\n",
    "# Activation functions used for building the uneducated predictor\n",
    "\n",
    "ACTIVATION: str = \"relu\"\n",
    "LAST_ACTIVATION: str = \"sigmoid\"\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "SEED = 0\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description, analysis and preprocessing\n",
    "(If you are interested only in the injection part you can skip this section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download (if not already present) train and test set.\n",
    "The dataset contains general information about individuals (e.g., age, sex, education, etc.) and their yearly income (i.e., more or less than 50,000 USD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_processed_train = CensusIncome.get_train()\n",
    "not_processed_test = CensusIncome.get_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first look to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       Age          WorkClass  Fnlwgt    Education  EducationNumeric  \\\n0       39          State-gov   77516    Bachelors                13   \n1       50   Self-emp-not-inc   83311    Bachelors                13   \n2       38            Private  215646      HS-grad                 9   \n3       53            Private  234721         11th                 7   \n4       28            Private  338409    Bachelors                13   \n...    ...                ...     ...          ...               ...   \n32556   27            Private  257302   Assoc-acdm                12   \n32557   40            Private  154374      HS-grad                 9   \n32558   58            Private  151910      HS-grad                 9   \n32559   22            Private  201490      HS-grad                 9   \n32560   52       Self-emp-inc  287927      HS-grad                 9   \n\n             MaritalStatus          Occupation    Relationship Ethnicity  \\\n0            Never-married        Adm-clerical   Not-in-family     White   \n1       Married-civ-spouse     Exec-managerial         Husband     White   \n2                 Divorced   Handlers-cleaners   Not-in-family     White   \n3       Married-civ-spouse   Handlers-cleaners         Husband     Black   \n4       Married-civ-spouse      Prof-specialty            Wife     Black   \n...                    ...                 ...             ...       ...   \n32556   Married-civ-spouse        Tech-support            Wife     White   \n32557   Married-civ-spouse   Machine-op-inspct         Husband     White   \n32558              Widowed        Adm-clerical       Unmarried     White   \n32559        Never-married        Adm-clerical       Own-child     White   \n32560   Married-civ-spouse     Exec-managerial            Wife     White   \n\n           Sex  CapitalGain  CapitalLoss  HoursPerWeek   NativeCountry  income  \n0         Male         2174            0            40   United-States   <=50K  \n1         Male            0            0            13   United-States   <=50K  \n2         Male            0            0            40   United-States   <=50K  \n3         Male            0            0            40   United-States   <=50K  \n4       Female            0            0            40            Cuba   <=50K  \n...        ...          ...          ...           ...             ...     ...  \n32556   Female            0            0            38   United-States   <=50K  \n32557     Male            0            0            40   United-States    >50K  \n32558   Female            0            0            40   United-States   <=50K  \n32559     Male            0            0            20   United-States   <=50K  \n32560   Female        15024            0            40   United-States    >50K  \n\n[32561 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>WorkClass</th>\n      <th>Fnlwgt</th>\n      <th>Education</th>\n      <th>EducationNumeric</th>\n      <th>MaritalStatus</th>\n      <th>Occupation</th>\n      <th>Relationship</th>\n      <th>Ethnicity</th>\n      <th>Sex</th>\n      <th>CapitalGain</th>\n      <th>CapitalLoss</th>\n      <th>HoursPerWeek</th>\n      <th>NativeCountry</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32556</th>\n      <td>27</td>\n      <td>Private</td>\n      <td>257302</td>\n      <td>Assoc-acdm</td>\n      <td>12</td>\n      <td>Married-civ-spouse</td>\n      <td>Tech-support</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32557</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>154374</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>32558</th>\n      <td>58</td>\n      <td>Private</td>\n      <td>151910</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Widowed</td>\n      <td>Adm-clerical</td>\n      <td>Unmarried</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32559</th>\n      <td>22</td>\n      <td>Private</td>\n      <td>201490</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>32560</th>\n      <td>52</td>\n      <td>Self-emp-inc</td>\n      <td>287927</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>15024</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n<p>32561 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_processed_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we are dealing with different data types. In particular:\n",
    "- Age, Fnlwgt, CapitalGain, CapitalLoss and HoursPerWeek are continuous (integer) features;\n",
    "- EducationNumeric is ordinal;\n",
    "- Sex is binary;\n",
    "- the remaining features are nominal (WorkClass, Education, MaritalStatus, Occupation, Relationship, NativeCountry)\n",
    "\n",
    "Ok. All feature names are self-explaining but Fnlwgt. What the hell is that?\n",
    "Fnlwgt stands for FinalWeight, and it is a popular belief that it should indicate the estimated number of people represented by the row.\n",
    "However, if we simply compute the sum of this feature along all the dataset (train and test) this value is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'12,358,746,784'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{sum(not_processed_train.Fnlwgt) + sum(not_processed_test.Fnlwgt):,}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so more than 9 billions, this is more than the actual Earth population! (and this is a dataset from the 90s concerning only the US)\n",
    "Therefore, this is not the correct interpretation of this feature.\n",
    "\n",
    "The actual meaning of Fnlwgt is much more complicated. If we look at the original data description available [here](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) we can read:\n",
    "\n",
    "> Description of fnlwgt (final weight)\n",
    ">\n",
    "> The weights on the CPS files are controlled to independent estimates of the\n",
    "civilian noninstitutional population of the US.  These are prepared monthly\n",
    "for us by Population Division here at the Census Bureau.  We use 3 sets of\n",
    "controls.\n",
    "These are:\n",
    "    1. A single cell estimate of the population 16+ for each state.\n",
    "    2. Controls for Hispanic Origin by age and sex.\n",
    "    3. Controls by Race, age and sex.\n",
    "\n",
    "> We use all three sets of controls in our weighting program and \"rake\" through\n",
    "them 6 times so that by the end we come back to all the controls we used.\n",
    ">\n",
    "> The term estimate refers to population totals derived from CPS by creating\n",
    "\"weighted tallies\" of any specified socio-economic characteristics of the\n",
    "population.\n",
    ">\n",
    "> People with similar demographic characteristics should have\n",
    "similar weights. There is one important caveat to remember\n",
    "about this statement. That is that since the CPS sample is\n",
    "actually a collection of 51 state samples, each with its own\n",
    "probability of selection, the statement only applies within\n",
    "state.\n",
    "\n",
    "Long story short, it is a similarity metric computed upon the other features.\n",
    "We can definitively ignore it in our study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "- Fnlwgt is discarded;\n",
    "- Education is discarded as well because EducationNumeric has the same information;\n",
    "- Sex is mapped into 0 (Male) and 1 (Female);\n",
    "- Income is mapped into 0 (<=50K) and 1 (>50K) as well;\n",
    "- The remaining nominal features are one-hot encoded (WorkClass, MaritalStatus, Occupation, Relationship, NativeCountry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "CapitalGain\n",
      "CapitalLoss\n",
      "EducationNumeric\n",
      "Ethnicity_amer_indian_eskimo\n",
      "Ethnicity_asian_pac_islander\n",
      "Ethnicity_black\n",
      "Ethnicity_other\n",
      "Ethnicity_white\n",
      "HoursPerWeek\n",
      "MaritalStatus_divorced\n",
      "MaritalStatus_married_af_spouse\n",
      "MaritalStatus_married_civ_spouse\n",
      "MaritalStatus_married_spouse_absent\n",
      "MaritalStatus_never_married\n",
      "MaritalStatus_separated\n",
      "MaritalStatus_widowed\n",
      "NativeCountry_cambodia\n",
      "NativeCountry_canada\n",
      "NativeCountry_china\n",
      "NativeCountry_columbia\n",
      "NativeCountry_cuba\n",
      "NativeCountry_dominican_republic\n",
      "NativeCountry_ecuador\n",
      "NativeCountry_el_salvador\n",
      "NativeCountry_england\n",
      "NativeCountry_france\n",
      "NativeCountry_germany\n",
      "NativeCountry_greece\n",
      "NativeCountry_guatemala\n",
      "NativeCountry_haiti\n",
      "NativeCountry_holand_netherlands\n",
      "NativeCountry_honduras\n",
      "NativeCountry_hong\n",
      "NativeCountry_hungary\n",
      "NativeCountry_india\n",
      "NativeCountry_iran\n",
      "NativeCountry_ireland\n",
      "NativeCountry_italy\n",
      "NativeCountry_jamaica\n",
      "NativeCountry_japan\n",
      "NativeCountry_laos\n",
      "NativeCountry_mexico\n",
      "NativeCountry_nicaragua\n",
      "NativeCountry_outlying_us\n",
      "NativeCountry_peru\n",
      "NativeCountry_philippines\n",
      "NativeCountry_poland\n",
      "NativeCountry_portugal\n",
      "NativeCountry_puerto_rico\n",
      "NativeCountry_scotland\n",
      "NativeCountry_south\n",
      "NativeCountry_taiwan\n",
      "NativeCountry_thailand\n",
      "NativeCountry_trinadad_tobago\n",
      "NativeCountry_united_states\n",
      "NativeCountry_unknown\n",
      "NativeCountry_vietnam\n",
      "NativeCountry_yugoslavia\n",
      "Occupation_adm_clerical\n",
      "Occupation_armed_forces\n",
      "Occupation_craft_repair\n",
      "Occupation_exec_managerial\n",
      "Occupation_farming_fishing\n",
      "Occupation_handlers_cleaners\n",
      "Occupation_machine_op_inspct\n",
      "Occupation_other_service\n",
      "Occupation_priv_house_serv\n",
      "Occupation_prof_specialty\n",
      "Occupation_protective_serv\n",
      "Occupation_sales\n",
      "Occupation_tech_support\n",
      "Occupation_transport_moving\n",
      "Occupation_unknown\n",
      "Relationship_husband\n",
      "Relationship_not_in_family\n",
      "Relationship_other_relative\n",
      "Relationship_own_child\n",
      "Relationship_unmarried\n",
      "Relationship_wife\n",
      "Sex\n",
      "WorkClass_federal_gov\n",
      "WorkClass_local_gov\n",
      "WorkClass_never_worked\n",
      "WorkClass_private\n",
      "WorkClass_self_emp_inc\n",
      "WorkClass_self_emp_not_inc\n",
      "WorkClass_state_gov\n",
      "WorkClass_unknown\n",
      "WorkClass_without_pay\n",
      "income\n"
     ]
    },
    {
     "data": {
      "text/plain": "                Age   CapitalGain   CapitalLoss  EducationNumeric  \\\ncount  32561.000000  32561.000000  32561.000000      32561.000000   \nmean      38.581647   1077.648844     87.303830         10.080679   \nstd       13.640433   7385.292085    402.960219          2.572720   \nmin       17.000000      0.000000      0.000000          1.000000   \n25%       28.000000      0.000000      0.000000          9.000000   \n50%       37.000000      0.000000      0.000000         10.000000   \n75%       48.000000      0.000000      0.000000         12.000000   \nmax       90.000000  99999.000000   4356.000000         16.000000   \n\n       Ethnicity_amer_indian_eskimo  Ethnicity_asian_pac_islander  \\\ncount                  32561.000000                  32561.000000   \nmean                       0.009551                      0.031909   \nstd                        0.097264                      0.175761   \nmin                        0.000000                      0.000000   \n25%                        0.000000                      0.000000   \n50%                        0.000000                      0.000000   \n75%                        0.000000                      0.000000   \nmax                        1.000000                      1.000000   \n\n       Ethnicity_black  Ethnicity_other  Ethnicity_white  HoursPerWeek  ...  \\\ncount     32561.000000     32561.000000     32561.000000  32561.000000  ...   \nmean          0.095943         0.008323         0.854274     40.437456  ...   \nstd           0.294518         0.090851         0.352837     12.347429  ...   \nmin           0.000000         0.000000         0.000000      1.000000  ...   \n25%           0.000000         0.000000         1.000000     40.000000  ...   \n50%           0.000000         0.000000         1.000000     40.000000  ...   \n75%           0.000000         0.000000         1.000000     45.000000  ...   \nmax           1.000000         1.000000         1.000000     99.000000  ...   \n\n       WorkClass_federal_gov  WorkClass_local_gov  WorkClass_never_worked  \\\ncount           32561.000000         32561.000000            32561.000000   \nmean                0.029483             0.064279                0.000215   \nstd                 0.169159             0.245254                0.014661   \nmin                 0.000000             0.000000                0.000000   \n25%                 0.000000             0.000000                0.000000   \n50%                 0.000000             0.000000                0.000000   \n75%                 0.000000             0.000000                0.000000   \nmax                 1.000000             1.000000                1.000000   \n\n       WorkClass_private  WorkClass_self_emp_inc  WorkClass_self_emp_not_inc  \\\ncount       32561.000000            32561.000000                32561.000000   \nmean            0.697030                0.034274                    0.078038   \nstd             0.459549                0.181935                    0.268236   \nmin             0.000000                0.000000                    0.000000   \n25%             0.000000                0.000000                    0.000000   \n50%             1.000000                0.000000                    0.000000   \n75%             1.000000                0.000000                    0.000000   \nmax             1.000000                1.000000                    1.000000   \n\n       WorkClass_state_gov  WorkClass_unknown  WorkClass_without_pay  \\\ncount         32561.000000       32561.000000           32561.000000   \nmean              0.039864           0.056386               0.000430   \nstd               0.195642           0.230670               0.020731   \nmin               0.000000           0.000000               0.000000   \n25%               0.000000           0.000000               0.000000   \n50%               0.000000           0.000000               0.000000   \n75%               0.000000           0.000000               0.000000   \nmax               1.000000           1.000000               1.000000   \n\n             income  \ncount  32561.000000  \nmean       0.240810  \nstd        0.427581  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  \n\n[8 rows x 91 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>CapitalGain</th>\n      <th>CapitalLoss</th>\n      <th>EducationNumeric</th>\n      <th>Ethnicity_amer_indian_eskimo</th>\n      <th>Ethnicity_asian_pac_islander</th>\n      <th>Ethnicity_black</th>\n      <th>Ethnicity_other</th>\n      <th>Ethnicity_white</th>\n      <th>HoursPerWeek</th>\n      <th>...</th>\n      <th>WorkClass_federal_gov</th>\n      <th>WorkClass_local_gov</th>\n      <th>WorkClass_never_worked</th>\n      <th>WorkClass_private</th>\n      <th>WorkClass_self_emp_inc</th>\n      <th>WorkClass_self_emp_not_inc</th>\n      <th>WorkClass_state_gov</th>\n      <th>WorkClass_unknown</th>\n      <th>WorkClass_without_pay</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>...</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n      <td>32561.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>38.581647</td>\n      <td>1077.648844</td>\n      <td>87.303830</td>\n      <td>10.080679</td>\n      <td>0.009551</td>\n      <td>0.031909</td>\n      <td>0.095943</td>\n      <td>0.008323</td>\n      <td>0.854274</td>\n      <td>40.437456</td>\n      <td>...</td>\n      <td>0.029483</td>\n      <td>0.064279</td>\n      <td>0.000215</td>\n      <td>0.697030</td>\n      <td>0.034274</td>\n      <td>0.078038</td>\n      <td>0.039864</td>\n      <td>0.056386</td>\n      <td>0.000430</td>\n      <td>0.240810</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>13.640433</td>\n      <td>7385.292085</td>\n      <td>402.960219</td>\n      <td>2.572720</td>\n      <td>0.097264</td>\n      <td>0.175761</td>\n      <td>0.294518</td>\n      <td>0.090851</td>\n      <td>0.352837</td>\n      <td>12.347429</td>\n      <td>...</td>\n      <td>0.169159</td>\n      <td>0.245254</td>\n      <td>0.014661</td>\n      <td>0.459549</td>\n      <td>0.181935</td>\n      <td>0.268236</td>\n      <td>0.195642</td>\n      <td>0.230670</td>\n      <td>0.020731</td>\n      <td>0.427581</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>17.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>40.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>37.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>40.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>48.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>12.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>45.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>90.000000</td>\n      <td>99999.000000</td>\n      <td>4356.000000</td>\n      <td>16.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>99.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 91 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset = CensusIncome.get_processed_dataset(pd.concat((not_processed_train, not_processed_test), axis=0))\n",
    "train = processed_dataset.iloc[:not_processed_train.shape[0], :]\n",
    "test = processed_dataset.iloc[not_processed_train.shape[0]:, :]\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How features are correlated with the target variable income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "income                              1.000000\nMaritalStatus_married_civ_spouse    0.444696\nRelationship_husband                0.401035\nEducationNumeric                    0.335154\nAge                                 0.234037\n                                      ...   \nOccupation_other_service           -0.156348\nRelationship_not_in_family         -0.188497\nSex                                -0.215980\nRelationship_own_child             -0.228532\nMaritalStatus_never_married        -0.318440\nName: income, Length: 91, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr().income.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='injection'></a>\n",
    "## Injection\n",
    "\n",
    "### Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge = TuProlog.from_file(CENSUS_KNOWLEDGE_FILE)\n",
    "theory = Theory(knowledge, train)\n",
    "\n",
    "# You can also create a theory in one single line providing the file path of the knowledge instead of the knowledge itself.\n",
    "# theory = Theory(CENSUS_KNOWLEDGE_FILE, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This knowledge is extracted from a decision tree trained on the train dataset.\n",
    "The overall accuracy of the tree is 84.9% on the train set.\n",
    "It consists in the following 10 rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EducationNumeric > 12.0, MaritalStatus_married_civ_spouse > 0.0 -> 1.0\n",
      "EducationNumeric < 12.0, CapitalGain < 5119.0, CapitalLoss < 1820.0 -> 0.0\n",
      "EducationNumeric > 12.0, MaritalStatus_married_civ_spouse < 0.0, CapitalGain < 7073.0 -> 0.0\n",
      "EducationNumeric > 12.0, MaritalStatus_married_civ_spouse < 0.0, CapitalGain > 7073.0 -> 1.0\n",
      "CapitalGain < 5119.0, CapitalLoss > 1820.0, MaritalStatus_married_civ_spouse < 0.0 -> 0.0\n",
      "CapitalGain < 5119.0, CapitalLoss > 1820.0, MaritalStatus_married_civ_spouse > 0.0, EducationNumeric < 8.0 -> 0.0\n",
      "CapitalGain < 5119.0, CapitalLoss > 1820.0, MaritalStatus_married_civ_spouse > 0.0, EducationNumeric > 8.0 -> 1.0\n",
      "CapitalGain > 7073.0 -> 1.0\n",
      "MaritalStatus_married_civ_spouse < 0.0 -> 0.0\n",
      "True -> 1.0\n"
     ]
    }
   ],
   "source": [
    "for rule in theory.formulae:\n",
    "    print(f\"{rule.rhs} -> {rule.lhs.args.last}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is possible to specify that a certain rule is trainable, i.e., the weights and biases of neurons corresponding to the logic rule are affected by the training process.\n",
    "Usually, allowing the training of all rules means that the training is slower but accuracy should be higher.\n",
    "In this case, we choose not to train the rules."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# You can make all rules trainable by running the following line\n",
    "theory.set_all_formulae_trainable()\n",
    "\n",
    "# You can also make specific rules trainable by running the following line\n",
    "theory.set_formulae_trainable([\"class\"])  # class is the name of the rule (i.e., the name of the predicate)\n",
    "\n",
    "# To make all rules not trainable (a.k.a. static) run the following line\n",
    "theory.set_all_formulae_static()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual injection is as simple as that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "# Here we create a fully-connected NN with 1 hidden layer of 10 neurons\n",
    "uneducated = create_uneducated_predictor(train.shape[1]-1, 1, [10], ACTIVATION, LAST_ACTIVATION)\n",
    "injector = Injector.kins(uneducated)\n",
    "educated = injector.inject(theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='training'></a>\n",
    "## Training and evaluation\n",
    "\n",
    "From now on it is just the same as a common ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 12:55:23.072287: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1018/1018 [==============================] - 2s 728us/step - loss: 0.9998 - accuracy: 0.8007\n",
      "Epoch 2/20\n",
      "1018/1018 [==============================] - 1s 661us/step - loss: 0.4367 - accuracy: 0.8371\n",
      "Epoch 3/20\n",
      "1018/1018 [==============================] - 1s 688us/step - loss: 0.4063 - accuracy: 0.8418\n",
      "Epoch 4/20\n",
      "1018/1018 [==============================] - 1s 621us/step - loss: 0.4515 - accuracy: 0.8454\n",
      "Epoch 5/20\n",
      "1018/1018 [==============================] - 1s 670us/step - loss: 0.4588 - accuracy: 0.8453\n",
      "Epoch 6/20\n",
      "1018/1018 [==============================] - 1s 707us/step - loss: 0.3789 - accuracy: 0.8454\n",
      "Epoch 7/20\n",
      "1018/1018 [==============================] - 1s 731us/step - loss: 0.3826 - accuracy: 0.8482\n",
      "Epoch 8/20\n",
      "1018/1018 [==============================] - 1s 709us/step - loss: 0.4468 - accuracy: 0.8468\n",
      "Epoch 9/20\n",
      "1018/1018 [==============================] - 1s 650us/step - loss: 0.4539 - accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "1018/1018 [==============================] - 1s 620us/step - loss: 0.3676 - accuracy: 0.8498\n",
      "Epoch 11/20\n",
      "1018/1018 [==============================] - 1s 645us/step - loss: 0.4357 - accuracy: 0.8485\n",
      "Epoch 12/20\n",
      "1018/1018 [==============================] - 1s 646us/step - loss: 0.3594 - accuracy: 0.8513\n",
      "Epoch 13/20\n",
      "1018/1018 [==============================] - 1s 663us/step - loss: 0.4526 - accuracy: 0.8488\n",
      "Epoch 14/20\n",
      "1018/1018 [==============================] - 1s 669us/step - loss: 0.4029 - accuracy: 0.8511\n",
      "Epoch 15/20\n",
      "1018/1018 [==============================] - 1s 645us/step - loss: 0.3773 - accuracy: 0.8519\n",
      "Epoch 16/20\n",
      "1018/1018 [==============================] - 1s 830us/step - loss: 0.3785 - accuracy: 0.8508\n",
      "Epoch 17/20\n",
      "1018/1018 [==============================] - 1s 680us/step - loss: 0.4120 - accuracy: 0.8521\n",
      "Epoch 18/20\n",
      "1018/1018 [==============================] - 1s 636us/step - loss: 0.3719 - accuracy: 0.8509\n",
      "Epoch 19/20\n",
      "1018/1018 [==============================] - 1s 631us/step - loss: 0.3775 - accuracy: 0.8524\n",
      "Epoch 20/20\n",
      "1018/1018 [==============================] - 1s 667us/step - loss: 0.3753 - accuracy: 0.8533\n"
     ]
    }
   ],
   "source": [
    "educated.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_educated = educated.fit(train.iloc[:, :-1], train.iloc[:, -1], epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 1s 563us/step - loss: 0.3316 - accuracy: 0.8570\n",
      "test set accuracy of the educated predictor: 85.70%\n"
     ]
    }
   ],
   "source": [
    "_, acc = educated.evaluate(test.iloc[:, :-1], test.iloc[:, -1])\n",
    "print(f'test set accuracy of the educated predictor: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the uneducated predictor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1018/1018 [==============================] - 0s 350us/step - loss: 5.0308 - accuracy: 0.7680\n",
      "Epoch 2/20\n",
      "1018/1018 [==============================] - 0s 341us/step - loss: 0.4861 - accuracy: 0.8310\n",
      "Epoch 3/20\n",
      "1018/1018 [==============================] - 0s 350us/step - loss: 0.7865 - accuracy: 0.8339\n",
      "Epoch 4/20\n",
      "1018/1018 [==============================] - 0s 335us/step - loss: 0.5931 - accuracy: 0.8391\n",
      "Epoch 5/20\n",
      "1018/1018 [==============================] - 0s 334us/step - loss: 0.6248 - accuracy: 0.8405\n",
      "Epoch 6/20\n",
      "1018/1018 [==============================] - 0s 332us/step - loss: 0.4600 - accuracy: 0.8428\n",
      "Epoch 7/20\n",
      "1018/1018 [==============================] - 0s 329us/step - loss: 0.4579 - accuracy: 0.8431\n",
      "Epoch 8/20\n",
      "1018/1018 [==============================] - 0s 332us/step - loss: 0.5925 - accuracy: 0.8431\n",
      "Epoch 9/20\n",
      "1018/1018 [==============================] - 0s 328us/step - loss: 0.6128 - accuracy: 0.8424\n",
      "Epoch 10/20\n",
      "1018/1018 [==============================] - 0s 329us/step - loss: 0.4300 - accuracy: 0.8452\n",
      "Epoch 11/20\n",
      "1018/1018 [==============================] - 0s 329us/step - loss: 0.5849 - accuracy: 0.8443\n",
      "Epoch 12/20\n",
      "1018/1018 [==============================] - 0s 329us/step - loss: 0.4354 - accuracy: 0.8481\n",
      "Epoch 13/20\n",
      "1018/1018 [==============================] - 0s 330us/step - loss: 0.6327 - accuracy: 0.8435\n",
      "Epoch 14/20\n",
      "1018/1018 [==============================] - 0s 329us/step - loss: 0.5407 - accuracy: 0.8440\n",
      "Epoch 15/20\n",
      "1018/1018 [==============================] - 0s 329us/step - loss: 0.5264 - accuracy: 0.8480\n",
      "Epoch 16/20\n",
      "1018/1018 [==============================] - 0s 327us/step - loss: 0.4599 - accuracy: 0.8463\n",
      "Epoch 17/20\n",
      "1018/1018 [==============================] - 0s 331us/step - loss: 0.5182 - accuracy: 0.8468\n",
      "Epoch 18/20\n",
      "1018/1018 [==============================] - 0s 331us/step - loss: 0.4895 - accuracy: 0.8465\n",
      "Epoch 19/20\n",
      "1018/1018 [==============================] - 0s 331us/step - loss: 0.4453 - accuracy: 0.8472\n",
      "Epoch 20/20\n",
      "1018/1018 [==============================] - 0s 330us/step - loss: 0.4588 - accuracy: 0.8473\n"
     ]
    }
   ],
   "source": [
    "uneducated.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "history_uneducated = uneducated.fit(train.iloc[:, :-1], train.iloc[:, -1], epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 0s 240us/step - loss: 0.3479 - accuracy: 0.8555\n",
      "test set accuracy of the uneducated predictor: 85.55%\n"
     ]
    }
   ],
   "source": [
    "_, acc = uneducated.evaluate(test.iloc[:, :-1], test.iloc[:, -1])\n",
    "print(f'test set accuracy of the uneducated predictor: {acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
