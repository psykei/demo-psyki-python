{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working demonstration of KINS injector using the Census Income dataset\n",
    "\n",
    "Notebook organisation:\n",
    "1. [**imports and utility functions**](#imports)\n",
    "2. [**dataset description, analysis and preprocessing**](#dataset-description,-analysis-and-preprocessing)\n",
    "3. [**injection**](#injection) (if you are interested only in the injection mechanism skip the other parts)\n",
    "4. [**training and evaluation**](#training-and-evaluation)\n",
    "\n",
    "Note: Internet connection is required to download the dataset.\n",
    "If the files of the Census Income dataset are in folder `data` Internet connection is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports and utility functions\n",
    "\n",
    "Some necessary imports:\n",
    "- __re__ for regex operations\n",
    "- __os__ to use other resources in this repository\n",
    "- __pandas__ for data retrieval and statistics\n",
    "- __tensorflow__ for neural networks\n",
    "- __psyki__ for symbolic knowledge injection\n",
    "- __typing__ for better quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.framework.random_seed import set_seed\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from psyki.logic import Theory\n",
    "from psyki.logic.prolog import TuProlog\n",
    "from psyki.ski import Injector\n",
    "\n",
    "os.getcwd()\n",
    "from knowledge import PATH as KNOWLEDGE_PATH\n",
    "from data import SpliceJunction\n",
    "from utils import create_uneducated_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLICE_KNOWLEDGE_FILE = str(KNOWLEDGE_PATH / SpliceJunction.knowledge_file_name)\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "SEED = 0\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description, analysis and preprocessing\n",
    "(If you are interested only in the injection part you can skip this section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download (if not already present) train and test set.\n",
    "The dataset contains a sequence of 60 nucleotides and a label.\n",
    "The label can be:\n",
    "- __ei__: Exon-intron boundary, parts of the DNA sequence that are retained after splicing (donors);\n",
    "- __ie__: Intron-exon boundary, parts of the DNA sequence that are spliced out (acceptors);\n",
    "- __n__: Non-splicing boundary, parts of the DNA sequence that are neither retained nor spliced out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_processed = SpliceJunction.get_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first look at the dataset:\n",
    "- 3190 samples in total, 2552 in the training set and 638 in the test set;\n",
    "- There are three columns, the first one is the label, the second one is the identifier of the sample and the third one is the sequence;\n",
    "- Classes are reparted as follows:\n",
    "    - ei: 768\n",
    "    - ie: 767\n",
    "    - n: 1655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       0                   1  \\\n0     EI    ATRINS-DONOR-521   \n1     EI    ATRINS-DONOR-905   \n2     EI    BABAPOE-DONOR-30   \n3     EI   BABAPOE-DONOR-867   \n4     EI  BABAPOE-DONOR-2817   \n...   ..                 ...   \n3185   N  ORAHBPSBD-NEG-2881   \n3186   N   ORAINVOL-NEG-2161   \n3187   N     ORARGIT-NEG-241   \n3188   N      TARHBB-NEG-541   \n3189   N     TARHBD-NEG-1981   \n\n                                                      2  \n0     CCAGCTGCATCACAGGAGGCCAGCGAGCAGGTCTGTTCCAAGGGCC...  \n1     AGACCCGCCGGGAGGCGGAGGACCTGCAGGGTGAGCCCCACCGCCC...  \n2     GAGGTGAAGGACGTCCTTCCCCAGGAGCCGGTGAGAAGCGCAGTCG...  \n3     GGGCTGCGTTGCTGGTCACATTCCTGGCAGGTATGGGGCGGGGCTT...  \n4     GCTCAGCCCCCAGGTCACCCAGGAACTGACGTGAGTGTCCCCATCC...  \n...                                                 ...  \n3185  TCTCTTCCCTTCCCCTCTCTCTTTCTTTCTTTTCTCTCCTCTTCTC...  \n3186  GAGCTCCCAGAGCAGCAAGAGGGCCAGCTGAAGCACCTGGAGAAGC...  \n3187  TCTCGGGGGCGGCCGGCGCGGCGGGGAGCGGTCCCCGGCCGCGGCC...  \n3188  ATTCTACTTAGTAAACATAATTTCTTGTGCTAGATAACCAAATTAA...  \n3189  AGGCTGCCTATCAGAAGGTGGTGGCTGGTGTGGCTGCTGCTCTGGC...  \n\n[3190 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EI</td>\n      <td>ATRINS-DONOR-521</td>\n      <td>CCAGCTGCATCACAGGAGGCCAGCGAGCAGGTCTGTTCCAAGGGCC...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EI</td>\n      <td>ATRINS-DONOR-905</td>\n      <td>AGACCCGCCGGGAGGCGGAGGACCTGCAGGGTGAGCCCCACCGCCC...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>EI</td>\n      <td>BABAPOE-DONOR-30</td>\n      <td>GAGGTGAAGGACGTCCTTCCCCAGGAGCCGGTGAGAAGCGCAGTCG...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>EI</td>\n      <td>BABAPOE-DONOR-867</td>\n      <td>GGGCTGCGTTGCTGGTCACATTCCTGGCAGGTATGGGGCGGGGCTT...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EI</td>\n      <td>BABAPOE-DONOR-2817</td>\n      <td>GCTCAGCCCCCAGGTCACCCAGGAACTGACGTGAGTGTCCCCATCC...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3185</th>\n      <td>N</td>\n      <td>ORAHBPSBD-NEG-2881</td>\n      <td>TCTCTTCCCTTCCCCTCTCTCTTTCTTTCTTTTCTCTCCTCTTCTC...</td>\n    </tr>\n    <tr>\n      <th>3186</th>\n      <td>N</td>\n      <td>ORAINVOL-NEG-2161</td>\n      <td>GAGCTCCCAGAGCAGCAAGAGGGCCAGCTGAAGCACCTGGAGAAGC...</td>\n    </tr>\n    <tr>\n      <th>3187</th>\n      <td>N</td>\n      <td>ORARGIT-NEG-241</td>\n      <td>TCTCGGGGGCGGCCGGCGCGGCGGGGAGCGGTCCCCGGCCGCGGCC...</td>\n    </tr>\n    <tr>\n      <th>3188</th>\n      <td>N</td>\n      <td>TARHBB-NEG-541</td>\n      <td>ATTCTACTTAGTAAACATAATTTCTTGTGCTAGATAACCAAATTAA...</td>\n    </tr>\n    <tr>\n      <th>3189</th>\n      <td>N</td>\n      <td>TARHBD-NEG-1981</td>\n      <td>AGGCTGCCTATCAGAAGGTGGTGGCTGGTGTGGCTGCTGCTCTGGC...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3190 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "- we discard columns 1 and create 60 new features from column 2;\n",
    "- we then expand the 60 features into **4 x 60 = 240** new features. We basically create 4 new features for each of the 60 nucleotides. Each of the 4 new features is a binary feature that is 1 if the nucleotide is A, C, G or T respectively (multi-hot encoding). This is done because there are other symbols other than A, C, G and T in the dataset (e.g., the symbol M is used to represent a nucleotide that can be both A or C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      X_30a  X_30c  X_30g  X_30t  X_29a  X_29c  X_29g  X_29t  X_28a  X_28c  \\\n2093      0      0      1      0      0      0      1      0      1      0   \n1603      0      1      0      0      0      0      0      1      0      1   \n755       1      0      0      0      1      0      0      0      0      0   \n1316      0      0      0      1      0      0      0      1      0      0   \n1040      0      0      1      0      1      0      0      0      0      1   \n...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n475       0      1      0      0      0      0      0      1      0      0   \n467       0      0      1      0      0      0      1      0      0      1   \n1536      1      0      0      0      0      0      1      0      0      0   \n2144      0      1      0      0      0      0      0      1      0      0   \n2211      0      0      0      1      0      0      0      1      0      0   \n\n      ...  X28t  X29a  X29c  X29g  X29t  X30a  X30c  X30g  X30t  240  \n2093  ...     0     0     0     1     0     0     0     1     0    2  \n1603  ...     0     1     0     0     0     0     0     0     1    2  \n755   ...     1     0     1     0     0     0     0     0     1    0  \n1316  ...     1     1     0     0     0     0     0     1     0    1  \n1040  ...     0     0     1     0     0     0     0     0     1    1  \n...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...  \n475   ...     0     1     0     0     0     0     0     1     0    0  \n467   ...     0     0     0     0     1     0     0     1     0    0  \n1536  ...     0     0     0     1     0     0     0     1     0    2  \n2144  ...     0     1     0     0     0     0     1     0     0    2  \n2211  ...     0     1     0     0     0     0     0     1     0    2  \n\n[2190 rows x 241 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_30a</th>\n      <th>X_30c</th>\n      <th>X_30g</th>\n      <th>X_30t</th>\n      <th>X_29a</th>\n      <th>X_29c</th>\n      <th>X_29g</th>\n      <th>X_29t</th>\n      <th>X_28a</th>\n      <th>X_28c</th>\n      <th>...</th>\n      <th>X28t</th>\n      <th>X29a</th>\n      <th>X29c</th>\n      <th>X29g</th>\n      <th>X29t</th>\n      <th>X30a</th>\n      <th>X30c</th>\n      <th>X30g</th>\n      <th>X30t</th>\n      <th>240</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2093</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1603</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1316</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1040</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1536</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2144</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2211</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2190 rows Ã— 241 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset = SpliceJunction.get_processed_dataset(not_processed)\n",
    "train, test = train_test_split(processed_dataset, test_size=1000, random_state=SEED, stratify=processed_dataset.iloc[:, -1])\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='injection'></a>\n",
    "## Injection\n",
    "\n",
    "### Knowledge\n",
    "\n",
    "The knowledge for this dataset has been already provided by domain experts.\n",
    "Rules include several predicates describing how a DNA sequence should be classified.\n",
    "The original theory that we have rewritten with the Prolog syntax can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/splice-junction-gene-sequences/splice.theory).\n",
    "To keep it short, there are two stopping predicates, one for the exon-intron class and one for the intron-exon class.\n",
    "If the stopping predicate is met, then the DNA sequence shouldn't be classified for that class.\n",
    "There are other conditions that affect the classification rules but this goes out of the scope of this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge = TuProlog.from_file(SPLICE_KNOWLEDGE_FILE)\n",
    "theory = Theory(knowledge, train, SpliceJunction.class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "ei_stop\n",
      "exon_intron\n",
      "ie_stop\n",
      "intron_exon\n",
      "m_of_n\n",
      "pyramidine_rich\n"
     ]
    }
   ],
   "source": [
    "for rule_name in sorted(set([rule.lhs.predication for rule in theory.formulae])):\n",
    "    print(rule_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make all rules trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory.set_all_formulae_trainable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual injection is as simple as that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "# Here we create a fully-connected NN with no hidden layer.\n",
    "# It is not important to use a NN with hidden layers because the KBANN algorithm build an educated NN from scratch starting from the theory.\n",
    "# So, here we simply pass a NN just for retrieve the number of input features and the number of output\n",
    "# Indeed, the need for a predictor it is not strictly necessary but in this way it is uniform with the other injectors.\n",
    "uneducated = create_uneducated_predictor(train.shape[1]-1, 3, [])\n",
    "injector = Injector.kbann(uneducated)\n",
    "educated = injector.inject(theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='training'></a>\n",
    "## Training and evaluation\n",
    "\n",
    "From now on it is just the same as a common ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 18:17:47.451812: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/69 [==============================] - 2s 2ms/step - loss: 3.0806 - accuracy: 0.5242\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.9041 - accuracy: 0.5279\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.7361 - accuracy: 0.5279\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.5768 - accuracy: 0.5279\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.4246 - accuracy: 0.5306\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.2791 - accuracy: 0.5342\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.1404 - accuracy: 0.5347\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 2.0086 - accuracy: 0.5420\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 1.8829 - accuracy: 0.5868\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.7661 - accuracy: 0.5963\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.6581 - accuracy: 0.5963\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.5577 - accuracy: 0.5968\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.4654 - accuracy: 0.6151\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.3802 - accuracy: 0.7023\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.3033 - accuracy: 0.7178\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.2351 - accuracy: 0.7210\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.1748 - accuracy: 0.7256\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.1211 - accuracy: 0.7288\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.0732 - accuracy: 0.7320\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 1.0293 - accuracy: 0.7342\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.9892 - accuracy: 0.7361\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.9518 - accuracy: 0.7365\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.9168 - accuracy: 0.7361\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8534 - accuracy: 0.7466\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.8251 - accuracy: 0.7635\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7985 - accuracy: 0.7749\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7740 - accuracy: 0.7804\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7515 - accuracy: 0.7826\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7307 - accuracy: 0.7973\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.8100\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.8114\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.8119\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.8128\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.8128\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.8137\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.8132\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.8132\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.8128\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.8132\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.8128\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.8123\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.8128\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.8132\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.8132\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.8128\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8123\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8123\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8128\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8123\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8123\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8119\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8119\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8119\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8119\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8119\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8119\n",
      "Epoch 58/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8119\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8119\n",
      "Epoch 60/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8114\n",
      "Epoch 61/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8575\n",
      "Epoch 62/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8890\n",
      "Epoch 63/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8954\n",
      "Epoch 64/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8986\n",
      "Epoch 65/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.9041\n",
      "Epoch 66/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.9114\n",
      "Epoch 67/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.9137\n",
      "Epoch 68/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.9178\n",
      "Epoch 69/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.9187\n",
      "Epoch 70/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.9196\n",
      "Epoch 71/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.9196\n",
      "Epoch 72/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.9210\n",
      "Epoch 73/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.9215\n",
      "Epoch 74/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.9224\n",
      "Epoch 75/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9224\n",
      "Epoch 76/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.9224\n",
      "Epoch 77/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.9219\n",
      "Epoch 78/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.9196\n",
      "Epoch 79/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.9192\n",
      "Epoch 80/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.9192\n",
      "Epoch 81/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.9192\n",
      "Epoch 82/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.9201\n",
      "Epoch 83/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.9201\n",
      "Epoch 84/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.9201\n",
      "Epoch 85/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.9205\n",
      "Epoch 86/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9210\n",
      "Epoch 87/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9215\n",
      "Epoch 88/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.9210\n",
      "Epoch 89/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.9233\n",
      "Epoch 90/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.9247\n",
      "Epoch 91/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9269\n",
      "Epoch 92/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.9292\n",
      "Epoch 93/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.9292\n",
      "Epoch 94/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.9301\n",
      "Epoch 95/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9320\n",
      "Epoch 96/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9324\n",
      "Epoch 97/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.9329\n",
      "Epoch 98/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9333\n",
      "Epoch 99/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9333\n",
      "Epoch 100/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9342\n"
     ]
    }
   ],
   "source": [
    "educated.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "history_educated = educated.fit(train.iloc[:, :-1], to_categorical(train.iloc[:, -1]), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 779us/step - loss: 0.2162 - accuracy: 0.9350\n",
      "test set accuracy of the educated predictor: 93.50%\n"
     ]
    }
   ],
   "source": [
    "_, acc = educated.evaluate(test.iloc[:, :-1], to_categorical(test.iloc[:, -1]))\n",
    "print(f'test set accuracy of the educated predictor: {acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
